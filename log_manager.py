#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥å¿—ç®¡ç†å™¨ - ç»Ÿä¸€çš„æ—¥å¿—è½®è½¬å’Œæ¸…ç†æœºåˆ¶
"""

import logging
import logging.handlers
import os
import sys
from pathlib import Path
from datetime import datetime, timedelta
import gzip
import shutil
import asyncio
from typing import Optional

# ç¡®ä¿èƒ½æ‰¾åˆ°é…ç½®æ–‡ä»¶ - Dockerå’Œæœ¬åœ°ç¯å¢ƒå…¼å®¹
import os
if os.path.exists('app/backend/config.py'):
    # æœ¬åœ°å¼€å‘ç¯å¢ƒ
    sys.path.append('app/backend')
elif os.path.exists('config.py'):
    # Dockerç¯å¢ƒæˆ–æ ¹ç›®å½•è¿è¡Œ
    pass
else:
    # å°è¯•æ·»åŠ å¯èƒ½çš„è·¯å¾„
    sys.path.append('app/backend')

try:
    from config import Config
except ImportError as e:
    print(f"æ— æ³•å¯¼å…¥é…ç½®æ–‡ä»¶: {e}")
    # æä¾›é»˜è®¤é…ç½®
    class Config:
        MAX_LOG_SIZE = 100
        ENABLE_LOG_CLEANUP = True
        LOG_RETENTION_DAYS = 30
        LOG_CLEANUP_TIME = "02:00"
        LOG_LEVEL = "INFO"
        LOGS_DIR = "logs"


class LogRotationHandler(logging.handlers.RotatingFileHandler):
    """è‡ªå®šä¹‰æ—¥å¿—è½®è½¬å¤„ç†å™¨ï¼Œæ”¯æŒå‹ç¼©"""
    
    def __init__(self, filename, mode='a', maxBytes=0, backupCount=0, 
                 encoding=None, delay=False, compress=True):
        self.compress = compress
        super().__init__(filename, mode, maxBytes, backupCount, encoding, delay)
    
    def doRollover(self):
        """æ‰§è¡Œæ—¥å¿—è½®è½¬å¹¶å‹ç¼©æ—§æ–‡ä»¶"""
        if self.stream:
            self.stream.close()
            self.stream = None
            
        if self.backupCount > 0:
            for i in range(self.backupCount - 1, 0, -1):
                sfn = self.rotation_filename(f"{self.baseFilename}.{i}")
                dfn = self.rotation_filename(f"{self.baseFilename}.{i + 1}")
                if os.path.exists(sfn):
                    if os.path.exists(dfn):
                        os.remove(dfn)
                    os.rename(sfn, dfn)
            
            dfn = self.rotation_filename(self.baseFilename + ".1")
            if os.path.exists(dfn):
                os.remove(dfn)
                
            # ç§»åŠ¨å½“å‰æ–‡ä»¶åˆ° .1
            if os.path.exists(self.baseFilename):
                os.rename(self.baseFilename, dfn)
                
                # å‹ç¼©è½®è½¬çš„æ–‡ä»¶
                if self.compress and dfn.endswith('.1'):
                    self._compress_file(dfn)
        
        if not self.delay:
            self.stream = self._open()
    
    def _compress_file(self, filename):
        """å‹ç¼©æ—¥å¿—æ–‡ä»¶"""
        try:
            compressed_filename = f"{filename}.gz"
            with open(filename, 'rb') as f_in:
                with gzip.open(compressed_filename, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            os.remove(filename)
            print(f"ğŸ“¦ æ—¥å¿—æ–‡ä»¶å·²å‹ç¼©: {compressed_filename}")
        except Exception as e:
            print(f"âš ï¸ å‹ç¼©æ—¥å¿—æ–‡ä»¶å¤±è´¥ {filename}: {e}")


class LogManager:
    """ç»Ÿä¸€æ—¥å¿—ç®¡ç†å™¨"""
    
    def __init__(self):
        self.loggers = {}
        self.setup_directories()
    
    def setup_directories(self):
        """åˆ›å»ºæ—¥å¿—ç›®å½•"""
        log_dir = Path(Config.LOGS_DIR)
        log_dir.mkdir(parents=True, exist_ok=True)
    
    def get_logger(self, name: str, log_file: Optional[str] = None, 
                   max_bytes: int = 10*1024*1024, backup_count: int = 5) -> logging.Logger:
        """
        è·å–é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
        
        Args:
            name: æ—¥å¿—è®°å½•å™¨åç§°
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            max_bytes: å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°ï¼ˆå­—èŠ‚ï¼‰
            backup_count: ä¿ç•™çš„å¤‡ä»½æ–‡ä»¶æ•°é‡
        """
        if name in self.loggers:
            return self.loggers[name]
        
        logger = logging.getLogger(name)
        logger.setLevel(getattr(logging, Config.LOG_LEVEL.upper(), logging.INFO))
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        logger.handlers.clear()
        
        # åˆ›å»ºæ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s | %(levelname)s | %(name)s:%(funcName)s:%(lineno)d - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¦‚æœæŒ‡å®šäº†æ—¥å¿—æ–‡ä»¶ï¼‰
        if log_file:
            log_path = Path(Config.LOGS_DIR) / log_file
            log_path.parent.mkdir(parents=True, exist_ok=True)
            
            try:
                file_handler = LogRotationHandler(
                    filename=str(log_path),
                    maxBytes=max_bytes,
                    backupCount=backup_count,
                    encoding='utf-8',
                    compress=True
                )
                file_handler.setFormatter(formatter)
                logger.addHandler(file_handler)
                
                print(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶é…ç½®: {log_path} (æœ€å¤§: {max_bytes//1024//1024}MB, å¤‡ä»½: {backup_count}ä¸ª)")
                
            except (PermissionError, OSError) as e:
                print(f"âš ï¸ æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶ {log_path}: {e}")
                print("ğŸ“ æ—¥å¿—å°†ä»…è¾“å‡ºåˆ°æ§åˆ¶å°")
        
        self.loggers[name] = logger
        return logger
    
    def setup_main_loggers(self):
        """è®¾ç½®ä¸»è¦çš„æ—¥å¿—è®°å½•å™¨"""
        # ä¸»åº”ç”¨æ—¥å¿—
        main_logger = self.get_logger(
            'main', 
            'bot.log',
            max_bytes=Config.MAX_LOG_SIZE * 1024 * 1024,  # MBè½¬æ¢ä¸ºå­—èŠ‚
            backup_count=7
        )
        
        # WebæœåŠ¡æ—¥å¿—
        web_logger = self.get_logger(
            'web',
            'web_enhanced_clean.log',
            max_bytes=Config.MAX_LOG_SIZE * 1024 * 1024,
            backup_count=7
        )
        
        # Telegramå®¢æˆ·ç«¯æ—¥å¿—
        telegram_logger = self.get_logger(
            'telegram',
            'telegram_client.log',
            max_bytes=50 * 1024 * 1024,  # 50MB
            backup_count=5
        )
        
        # æ•°æ®åº“æ—¥å¿—
        db_logger = self.get_logger(
            'database',
            'database.log',
            max_bytes=20 * 1024 * 1024,  # 20MB
            backup_count=3
        )
        
        return {
            'main': main_logger,
            'web': web_logger,
            'telegram': telegram_logger,
            'database': db_logger
        }
    
    async def cleanup_old_logs(self):
        """æ¸…ç†è¿‡æœŸçš„æ—¥å¿—æ–‡ä»¶"""
        if not Config.ENABLE_LOG_CLEANUP:
            return
        
        log_dir = Path(Config.LOGS_DIR)
        if not log_dir.exists():
            return
        
        cutoff_date = datetime.now() - timedelta(days=Config.LOG_RETENTION_DAYS)
        cleaned_count = 0
        
        try:
            for log_file in log_dir.glob('*.log*'):
                if log_file.stat().st_mtime < cutoff_date.timestamp():
                    try:
                        log_file.unlink()
                        cleaned_count += 1
                        print(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸæ—¥å¿—: {log_file.name}")
                    except Exception as e:
                        print(f"âš ï¸ æ¸…ç†æ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_file}: {e}")
            
            if cleaned_count > 0:
                print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} ä¸ªè¿‡æœŸæ—¥å¿—æ–‡ä»¶")
            else:
                print("ğŸ“‹ æ²¡æœ‰å‘ç°è¿‡æœŸçš„æ—¥å¿—æ–‡ä»¶")
                
        except Exception as e:
            print(f"âŒ æ—¥å¿—æ¸…ç†å¤±è´¥: {e}")
    
    def get_log_stats(self):
        """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
        log_dir = Path(Config.LOGS_DIR)
        if not log_dir.exists():
            return {"total_files": 0, "total_size": 0}
        
        total_files = 0
        total_size = 0
        
        try:
            for log_file in log_dir.glob('*.log*'):
                if log_file.is_file():
                    total_files += 1
                    total_size += log_file.stat().st_size
            
            return {
                "total_files": total_files,
                "total_size": total_size,
                "total_size_mb": round(total_size / (1024 * 1024), 2)
            }
        except Exception as e:
            print(f"âš ï¸ è·å–æ—¥å¿—ç»Ÿè®¡å¤±è´¥: {e}")
            return {"total_files": 0, "total_size": 0, "error": str(e)}


# å…¨å±€æ—¥å¿—ç®¡ç†å™¨å®ä¾‹
log_manager = LogManager()

def get_logger(name: str, log_file: Optional[str] = None) -> logging.Logger:
    """è·å–æ—¥å¿—è®°å½•å™¨çš„ä¾¿æ·å‡½æ•°"""
    return log_manager.get_logger(name, log_file)

def setup_logging():
    """è®¾ç½®åº”ç”¨ç¨‹åºæ—¥å¿—"""
    return log_manager.setup_main_loggers()

async def schedule_log_cleanup():
    """å®šæ—¶æ—¥å¿—æ¸…ç†ä»»åŠ¡"""
    while True:
        try:
            # è§£ææ¸…ç†æ—¶é—´
            cleanup_time = Config.LOG_CLEANUP_TIME.split(':')
            cleanup_hour = int(cleanup_time[0])
            cleanup_minute = int(cleanup_time[1]) if len(cleanup_time) > 1 else 0
            
            now = datetime.now()
            next_cleanup = now.replace(hour=cleanup_hour, minute=cleanup_minute, second=0, microsecond=0)
            
            # å¦‚æœä»Šå¤©çš„æ¸…ç†æ—¶é—´å·²è¿‡ï¼Œè®¾ç½®ä¸ºæ˜å¤©
            if next_cleanup <= now:
                next_cleanup += timedelta(days=1)
            
            wait_seconds = (next_cleanup - now).total_seconds()
            print(f"ğŸ“… ä¸‹æ¬¡æ—¥å¿—æ¸…ç†æ—¶é—´: {next_cleanup.strftime('%Y-%m-%d %H:%M:%S')}")
            
            await asyncio.sleep(wait_seconds)
            await log_manager.cleanup_old_logs()
            
        except Exception as e:
            print(f"âŒ æ—¥å¿—æ¸…ç†è°ƒåº¦å¤±è´¥: {e}")
            # å‡ºé”™æ—¶ç­‰å¾…1å°æ—¶åé‡è¯•
            await asyncio.sleep(3600)
